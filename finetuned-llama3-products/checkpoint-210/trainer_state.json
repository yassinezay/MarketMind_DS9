{
  "best_global_step": null,
  "best_metric": null,
  "best_model_checkpoint": null,
  "epoch": 1.9488372093023256,
  "eval_steps": 500,
  "global_step": 210,
  "is_hyper_param_search": false,
  "is_local_process_zero": true,
  "is_world_process_zero": true,
  "log_history": [
    {
      "epoch": 0.009302325581395349,
      "grad_norm": 1.8735333681106567,
      "learning_rate": 0.0003,
      "loss": 3.2495,
      "step": 1
    },
    {
      "epoch": 0.018604651162790697,
      "grad_norm": 2.344085216522217,
      "learning_rate": 0.0002985981308411215,
      "loss": 3.2054,
      "step": 2
    },
    {
      "epoch": 0.027906976744186046,
      "grad_norm": 2.782209634780884,
      "learning_rate": 0.00029719626168224294,
      "loss": 2.7599,
      "step": 3
    },
    {
      "epoch": 0.037209302325581395,
      "grad_norm": 2.0672078132629395,
      "learning_rate": 0.0002957943925233645,
      "loss": 2.8265,
      "step": 4
    },
    {
      "epoch": 0.046511627906976744,
      "grad_norm": 2.312805414199829,
      "learning_rate": 0.00029439252336448596,
      "loss": 2.8088,
      "step": 5
    },
    {
      "epoch": 0.05581395348837209,
      "grad_norm": 2.2013251781463623,
      "learning_rate": 0.00029299065420560746,
      "loss": 2.6166,
      "step": 6
    },
    {
      "epoch": 0.06511627906976744,
      "grad_norm": 3.0223476886749268,
      "learning_rate": 0.0002915887850467289,
      "loss": 2.6872,
      "step": 7
    },
    {
      "epoch": 0.07441860465116279,
      "grad_norm": 2.4465832710266113,
      "learning_rate": 0.0002901869158878505,
      "loss": 1.7704,
      "step": 8
    },
    {
      "epoch": 0.08372093023255814,
      "grad_norm": 3.5412819385528564,
      "learning_rate": 0.00028878504672897194,
      "loss": 2.2275,
      "step": 9
    },
    {
      "epoch": 0.09302325581395349,
      "grad_norm": 3.1892521381378174,
      "learning_rate": 0.00028738317757009345,
      "loss": 2.2847,
      "step": 10
    },
    {
      "epoch": 0.10232558139534884,
      "grad_norm": 3.1282527446746826,
      "learning_rate": 0.0002859813084112149,
      "loss": 1.9158,
      "step": 11
    },
    {
      "epoch": 0.11162790697674418,
      "grad_norm": 3.084669351577759,
      "learning_rate": 0.00028457943925233646,
      "loss": 2.1198,
      "step": 12
    },
    {
      "epoch": 0.12093023255813953,
      "grad_norm": 4.796079158782959,
      "learning_rate": 0.0002831775700934579,
      "loss": 1.4981,
      "step": 13
    },
    {
      "epoch": 0.13023255813953488,
      "grad_norm": 5.081580638885498,
      "learning_rate": 0.0002817757009345794,
      "loss": 1.6431,
      "step": 14
    },
    {
      "epoch": 0.13953488372093023,
      "grad_norm": 4.288767337799072,
      "learning_rate": 0.0002803738317757009,
      "loss": 1.1025,
      "step": 15
    },
    {
      "epoch": 0.14883720930232558,
      "grad_norm": 2.9801392555236816,
      "learning_rate": 0.00027897196261682244,
      "loss": 2.0203,
      "step": 16
    },
    {
      "epoch": 0.15813953488372093,
      "grad_norm": 3.745976686477661,
      "learning_rate": 0.0002775700934579439,
      "loss": 1.4453,
      "step": 17
    },
    {
      "epoch": 0.16744186046511628,
      "grad_norm": 2.502445697784424,
      "learning_rate": 0.0002761682242990654,
      "loss": 1.1274,
      "step": 18
    },
    {
      "epoch": 0.17674418604651163,
      "grad_norm": 2.799546241760254,
      "learning_rate": 0.00027476635514018686,
      "loss": 1.5813,
      "step": 19
    },
    {
      "epoch": 0.18604651162790697,
      "grad_norm": 2.8671414852142334,
      "learning_rate": 0.0002733644859813084,
      "loss": 1.62,
      "step": 20
    },
    {
      "epoch": 0.19534883720930232,
      "grad_norm": 2.649900436401367,
      "learning_rate": 0.0002719626168224299,
      "loss": 1.3868,
      "step": 21
    },
    {
      "epoch": 0.20465116279069767,
      "grad_norm": 2.7610843181610107,
      "learning_rate": 0.0002705607476635514,
      "loss": 1.363,
      "step": 22
    },
    {
      "epoch": 0.21395348837209302,
      "grad_norm": 2.6815149784088135,
      "learning_rate": 0.00026915887850467284,
      "loss": 1.6281,
      "step": 23
    },
    {
      "epoch": 0.22325581395348837,
      "grad_norm": 1.9632283449172974,
      "learning_rate": 0.0002677570093457944,
      "loss": 0.8831,
      "step": 24
    },
    {
      "epoch": 0.23255813953488372,
      "grad_norm": 3.2100696563720703,
      "learning_rate": 0.00026635514018691586,
      "loss": 1.8838,
      "step": 25
    },
    {
      "epoch": 0.24186046511627907,
      "grad_norm": 4.004305362701416,
      "learning_rate": 0.00026495327102803737,
      "loss": 2.4075,
      "step": 26
    },
    {
      "epoch": 0.25116279069767444,
      "grad_norm": 1.995837926864624,
      "learning_rate": 0.0002635514018691588,
      "loss": 0.7537,
      "step": 27
    },
    {
      "epoch": 0.26046511627906976,
      "grad_norm": 2.866492509841919,
      "learning_rate": 0.0002621495327102804,
      "loss": 1.9225,
      "step": 28
    },
    {
      "epoch": 0.26976744186046514,
      "grad_norm": 4.020200729370117,
      "learning_rate": 0.00026074766355140184,
      "loss": 1.9441,
      "step": 29
    },
    {
      "epoch": 0.27906976744186046,
      "grad_norm": 4.903921127319336,
      "learning_rate": 0.00025934579439252335,
      "loss": 2.219,
      "step": 30
    },
    {
      "epoch": 0.28837209302325584,
      "grad_norm": 2.377619743347168,
      "learning_rate": 0.0002579439252336448,
      "loss": 1.234,
      "step": 31
    },
    {
      "epoch": 0.29767441860465116,
      "grad_norm": 2.616215944290161,
      "learning_rate": 0.00025654205607476637,
      "loss": 1.306,
      "step": 32
    },
    {
      "epoch": 0.30697674418604654,
      "grad_norm": 2.793401002883911,
      "learning_rate": 0.0002551401869158878,
      "loss": 1.6712,
      "step": 33
    },
    {
      "epoch": 0.31627906976744186,
      "grad_norm": 2.990384578704834,
      "learning_rate": 0.00025373831775700933,
      "loss": 1.673,
      "step": 34
    },
    {
      "epoch": 0.32558139534883723,
      "grad_norm": 3.5315349102020264,
      "learning_rate": 0.0002523364485981308,
      "loss": 1.1996,
      "step": 35
    },
    {
      "epoch": 0.33488372093023255,
      "grad_norm": 2.582379102706909,
      "learning_rate": 0.00025093457943925235,
      "loss": 1.0388,
      "step": 36
    },
    {
      "epoch": 0.34418604651162793,
      "grad_norm": 5.30885124206543,
      "learning_rate": 0.0002495327102803738,
      "loss": 1.9705,
      "step": 37
    },
    {
      "epoch": 0.35348837209302325,
      "grad_norm": 2.815953016281128,
      "learning_rate": 0.0002481308411214953,
      "loss": 0.9634,
      "step": 38
    },
    {
      "epoch": 0.3627906976744186,
      "grad_norm": 2.8243818283081055,
      "learning_rate": 0.00024672897196261677,
      "loss": 1.1455,
      "step": 39
    },
    {
      "epoch": 0.37209302325581395,
      "grad_norm": 3.6937496662139893,
      "learning_rate": 0.00024532710280373833,
      "loss": 1.431,
      "step": 40
    },
    {
      "epoch": 0.3813953488372093,
      "grad_norm": 2.3668134212493896,
      "learning_rate": 0.0002439252336448598,
      "loss": 0.9454,
      "step": 41
    },
    {
      "epoch": 0.39069767441860465,
      "grad_norm": 2.2971696853637695,
      "learning_rate": 0.0002425233644859813,
      "loss": 0.6423,
      "step": 42
    },
    {
      "epoch": 0.4,
      "grad_norm": 2.3331120014190674,
      "learning_rate": 0.00024112149532710278,
      "loss": 0.7212,
      "step": 43
    },
    {
      "epoch": 0.40930232558139534,
      "grad_norm": 5.140654563903809,
      "learning_rate": 0.00023971962616822429,
      "loss": 1.9137,
      "step": 44
    },
    {
      "epoch": 0.4186046511627907,
      "grad_norm": 4.781942844390869,
      "learning_rate": 0.00023831775700934577,
      "loss": 1.5848,
      "step": 45
    },
    {
      "epoch": 0.42790697674418604,
      "grad_norm": 3.266544818878174,
      "learning_rate": 0.00023691588785046728,
      "loss": 1.0775,
      "step": 46
    },
    {
      "epoch": 0.4372093023255814,
      "grad_norm": 5.670223236083984,
      "learning_rate": 0.00023551401869158876,
      "loss": 2.2537,
      "step": 47
    },
    {
      "epoch": 0.44651162790697674,
      "grad_norm": 2.666865348815918,
      "learning_rate": 0.00023411214953271027,
      "loss": 1.2798,
      "step": 48
    },
    {
      "epoch": 0.4558139534883721,
      "grad_norm": 4.168582916259766,
      "learning_rate": 0.00023271028037383175,
      "loss": 1.4782,
      "step": 49
    },
    {
      "epoch": 0.46511627906976744,
      "grad_norm": 1.5349478721618652,
      "learning_rate": 0.00023130841121495326,
      "loss": 0.365,
      "step": 50
    },
    {
      "epoch": 0.4744186046511628,
      "grad_norm": 5.028288841247559,
      "learning_rate": 0.00022990654205607474,
      "loss": 1.9403,
      "step": 51
    },
    {
      "epoch": 0.48372093023255813,
      "grad_norm": 4.025243759155273,
      "learning_rate": 0.00022850467289719625,
      "loss": 1.5341,
      "step": 52
    },
    {
      "epoch": 0.4930232558139535,
      "grad_norm": 2.89603328704834,
      "learning_rate": 0.00022710280373831773,
      "loss": 1.0478,
      "step": 53
    },
    {
      "epoch": 0.5023255813953489,
      "grad_norm": 3.6873698234558105,
      "learning_rate": 0.00022570093457943924,
      "loss": 0.8467,
      "step": 54
    },
    {
      "epoch": 0.5116279069767442,
      "grad_norm": 2.938131809234619,
      "learning_rate": 0.00022429906542056072,
      "loss": 0.6418,
      "step": 55
    },
    {
      "epoch": 0.5209302325581395,
      "grad_norm": 5.407279014587402,
      "learning_rate": 0.00022289719626168223,
      "loss": 1.0313,
      "step": 56
    },
    {
      "epoch": 0.5302325581395348,
      "grad_norm": 3.2611587047576904,
      "learning_rate": 0.0002214953271028037,
      "loss": 0.909,
      "step": 57
    },
    {
      "epoch": 0.5395348837209303,
      "grad_norm": 11.381546020507812,
      "learning_rate": 0.00022009345794392522,
      "loss": 1.0785,
      "step": 58
    },
    {
      "epoch": 0.5488372093023256,
      "grad_norm": 3.384878158569336,
      "learning_rate": 0.0002186915887850467,
      "loss": 0.8579,
      "step": 59
    },
    {
      "epoch": 0.5581395348837209,
      "grad_norm": 6.2760910987854,
      "learning_rate": 0.0002172897196261682,
      "loss": 1.7094,
      "step": 60
    },
    {
      "epoch": 0.5674418604651162,
      "grad_norm": 1.9695720672607422,
      "learning_rate": 0.0002158878504672897,
      "loss": 0.6079,
      "step": 61
    },
    {
      "epoch": 0.5767441860465117,
      "grad_norm": 3.5906310081481934,
      "learning_rate": 0.0002144859813084112,
      "loss": 1.3824,
      "step": 62
    },
    {
      "epoch": 0.586046511627907,
      "grad_norm": 8.635337829589844,
      "learning_rate": 0.00021308411214953268,
      "loss": 1.9776,
      "step": 63
    },
    {
      "epoch": 0.5953488372093023,
      "grad_norm": 3.071855306625366,
      "learning_rate": 0.0002116822429906542,
      "loss": 0.9117,
      "step": 64
    },
    {
      "epoch": 0.6046511627906976,
      "grad_norm": 2.8147494792938232,
      "learning_rate": 0.00021028037383177567,
      "loss": 0.7385,
      "step": 65
    },
    {
      "epoch": 0.6139534883720931,
      "grad_norm": 3.0854222774505615,
      "learning_rate": 0.00020887850467289718,
      "loss": 1.0523,
      "step": 66
    },
    {
      "epoch": 0.6232558139534884,
      "grad_norm": 5.01276159286499,
      "learning_rate": 0.00020747663551401867,
      "loss": 1.4668,
      "step": 67
    },
    {
      "epoch": 0.6325581395348837,
      "grad_norm": 2.2842087745666504,
      "learning_rate": 0.00020607476635514017,
      "loss": 0.516,
      "step": 68
    },
    {
      "epoch": 0.641860465116279,
      "grad_norm": 2.2263951301574707,
      "learning_rate": 0.00020467289719626166,
      "loss": 0.8321,
      "step": 69
    },
    {
      "epoch": 0.6511627906976745,
      "grad_norm": 1.3056104183197021,
      "learning_rate": 0.00020327102803738316,
      "loss": 0.2273,
      "step": 70
    },
    {
      "epoch": 0.6604651162790698,
      "grad_norm": 5.644335746765137,
      "learning_rate": 0.00020186915887850465,
      "loss": 2.4163,
      "step": 71
    },
    {
      "epoch": 0.6697674418604651,
      "grad_norm": 3.128972053527832,
      "learning_rate": 0.00020046728971962616,
      "loss": 1.4428,
      "step": 72
    },
    {
      "epoch": 0.6790697674418604,
      "grad_norm": 1.3069422245025635,
      "learning_rate": 0.00019906542056074764,
      "loss": 0.1784,
      "step": 73
    },
    {
      "epoch": 0.6883720930232559,
      "grad_norm": 5.858181953430176,
      "learning_rate": 0.00019766355140186915,
      "loss": 1.8692,
      "step": 74
    },
    {
      "epoch": 0.6976744186046512,
      "grad_norm": 2.965681791305542,
      "learning_rate": 0.00019626168224299063,
      "loss": 0.814,
      "step": 75
    },
    {
      "epoch": 0.7069767441860465,
      "grad_norm": 3.1734588146209717,
      "learning_rate": 0.00019485981308411214,
      "loss": 0.6289,
      "step": 76
    },
    {
      "epoch": 0.7162790697674418,
      "grad_norm": 4.288070201873779,
      "learning_rate": 0.00019345794392523362,
      "loss": 1.2385,
      "step": 77
    },
    {
      "epoch": 0.7255813953488373,
      "grad_norm": 1.6951578855514526,
      "learning_rate": 0.00019205607476635513,
      "loss": 0.2482,
      "step": 78
    },
    {
      "epoch": 0.7348837209302326,
      "grad_norm": 4.305999279022217,
      "learning_rate": 0.0001906542056074766,
      "loss": 1.8656,
      "step": 79
    },
    {
      "epoch": 0.7441860465116279,
      "grad_norm": 2.219648838043213,
      "learning_rate": 0.00018925233644859812,
      "loss": 0.7559,
      "step": 80
    },
    {
      "epoch": 0.7534883720930232,
      "grad_norm": 2.8924527168273926,
      "learning_rate": 0.0001878504672897196,
      "loss": 0.862,
      "step": 81
    },
    {
      "epoch": 0.7627906976744186,
      "grad_norm": 2.7741312980651855,
      "learning_rate": 0.0001864485981308411,
      "loss": 1.0486,
      "step": 82
    },
    {
      "epoch": 0.772093023255814,
      "grad_norm": 2.976311683654785,
      "learning_rate": 0.0001850467289719626,
      "loss": 0.8201,
      "step": 83
    },
    {
      "epoch": 0.7813953488372093,
      "grad_norm": 1.865231990814209,
      "learning_rate": 0.0001836448598130841,
      "loss": 0.155,
      "step": 84
    },
    {
      "epoch": 0.7906976744186046,
      "grad_norm": 2.350367307662964,
      "learning_rate": 0.00018224299065420558,
      "loss": 0.2707,
      "step": 85
    },
    {
      "epoch": 0.8,
      "grad_norm": 4.074813365936279,
      "learning_rate": 0.0001808411214953271,
      "loss": 1.095,
      "step": 86
    },
    {
      "epoch": 0.8093023255813954,
      "grad_norm": 2.15484356880188,
      "learning_rate": 0.00017943925233644857,
      "loss": 0.954,
      "step": 87
    },
    {
      "epoch": 0.8186046511627907,
      "grad_norm": 3.396306276321411,
      "learning_rate": 0.00017803738317757008,
      "loss": 0.4032,
      "step": 88
    },
    {
      "epoch": 0.827906976744186,
      "grad_norm": 2.681863307952881,
      "learning_rate": 0.00017663551401869156,
      "loss": 1.3025,
      "step": 89
    },
    {
      "epoch": 0.8372093023255814,
      "grad_norm": 2.7625815868377686,
      "learning_rate": 0.00017523364485981307,
      "loss": 1.3334,
      "step": 90
    },
    {
      "epoch": 0.8465116279069768,
      "grad_norm": 5.778120994567871,
      "learning_rate": 0.00017383177570093455,
      "loss": 1.5153,
      "step": 91
    },
    {
      "epoch": 0.8558139534883721,
      "grad_norm": 3.2492611408233643,
      "learning_rate": 0.00017242990654205606,
      "loss": 0.7907,
      "step": 92
    },
    {
      "epoch": 0.8651162790697674,
      "grad_norm": 4.830563068389893,
      "learning_rate": 0.00017102803738317754,
      "loss": 1.4892,
      "step": 93
    },
    {
      "epoch": 0.8744186046511628,
      "grad_norm": 3.8268544673919678,
      "learning_rate": 0.00016962616822429905,
      "loss": 0.9795,
      "step": 94
    },
    {
      "epoch": 0.8837209302325582,
      "grad_norm": 3.1348912715911865,
      "learning_rate": 0.00016822429906542053,
      "loss": 0.8679,
      "step": 95
    },
    {
      "epoch": 0.8930232558139535,
      "grad_norm": 1.1386849880218506,
      "learning_rate": 0.00016682242990654204,
      "loss": 0.129,
      "step": 96
    },
    {
      "epoch": 0.9023255813953488,
      "grad_norm": 3.61771559715271,
      "learning_rate": 0.00016542056074766352,
      "loss": 1.2514,
      "step": 97
    },
    {
      "epoch": 0.9116279069767442,
      "grad_norm": 2.716606855392456,
      "learning_rate": 0.00016401869158878503,
      "loss": 0.6833,
      "step": 98
    },
    {
      "epoch": 0.9209302325581395,
      "grad_norm": 0.8255061507225037,
      "learning_rate": 0.00016261682242990652,
      "loss": 0.0858,
      "step": 99
    },
    {
      "epoch": 0.9302325581395349,
      "grad_norm": 2.497529983520508,
      "learning_rate": 0.00016121495327102802,
      "loss": 0.9077,
      "step": 100
    },
    {
      "epoch": 0.9395348837209302,
      "grad_norm": 2.8456671237945557,
      "learning_rate": 0.0001598130841121495,
      "loss": 0.7525,
      "step": 101
    },
    {
      "epoch": 0.9488372093023256,
      "grad_norm": 4.153649806976318,
      "learning_rate": 0.00015841121495327101,
      "loss": 1.6477,
      "step": 102
    },
    {
      "epoch": 0.958139534883721,
      "grad_norm": 2.4345531463623047,
      "learning_rate": 0.0001570093457943925,
      "loss": 0.6517,
      "step": 103
    },
    {
      "epoch": 0.9674418604651163,
      "grad_norm": 1.814713716506958,
      "learning_rate": 0.000155607476635514,
      "loss": 0.2107,
      "step": 104
    },
    {
      "epoch": 0.9767441860465116,
      "grad_norm": 3.756645441055298,
      "learning_rate": 0.0001542056074766355,
      "loss": 0.9183,
      "step": 105
    },
    {
      "epoch": 0.986046511627907,
      "grad_norm": 3.443967580795288,
      "learning_rate": 0.000152803738317757,
      "loss": 1.0588,
      "step": 106
    },
    {
      "epoch": 0.9953488372093023,
      "grad_norm": 1.7193448543548584,
      "learning_rate": 0.00015140186915887848,
      "loss": 0.2446,
      "step": 107
    },
    {
      "epoch": 1.0,
      "grad_norm": 8.515769958496094,
      "learning_rate": 0.00015,
      "loss": 2.0316,
      "step": 108
    },
    {
      "epoch": 1.0093023255813953,
      "grad_norm": 3.2123239040374756,
      "learning_rate": 0.00014859813084112147,
      "loss": 0.5991,
      "step": 109
    },
    {
      "epoch": 1.0186046511627906,
      "grad_norm": 2.53084135055542,
      "learning_rate": 0.00014719626168224298,
      "loss": 0.3451,
      "step": 110
    },
    {
      "epoch": 1.027906976744186,
      "grad_norm": 2.921823024749756,
      "learning_rate": 0.00014579439252336446,
      "loss": 0.3226,
      "step": 111
    },
    {
      "epoch": 1.0372093023255813,
      "grad_norm": 1.8732917308807373,
      "learning_rate": 0.00014439252336448597,
      "loss": 0.2061,
      "step": 112
    },
    {
      "epoch": 1.0465116279069768,
      "grad_norm": 3.1429145336151123,
      "learning_rate": 0.00014299065420560745,
      "loss": 0.7662,
      "step": 113
    },
    {
      "epoch": 1.0558139534883721,
      "grad_norm": 4.6595330238342285,
      "learning_rate": 0.00014158878504672896,
      "loss": 1.4701,
      "step": 114
    },
    {
      "epoch": 1.0651162790697675,
      "grad_norm": 2.164844036102295,
      "learning_rate": 0.00014018691588785044,
      "loss": 0.2179,
      "step": 115
    },
    {
      "epoch": 1.0744186046511628,
      "grad_norm": 3.302891731262207,
      "learning_rate": 0.00013878504672897195,
      "loss": 0.7854,
      "step": 116
    },
    {
      "epoch": 1.083720930232558,
      "grad_norm": 2.711815357208252,
      "learning_rate": 0.00013738317757009343,
      "loss": 1.1234,
      "step": 117
    },
    {
      "epoch": 1.0930232558139534,
      "grad_norm": 4.627310752868652,
      "learning_rate": 0.00013598130841121494,
      "loss": 1.4169,
      "step": 118
    },
    {
      "epoch": 1.1023255813953488,
      "grad_norm": 2.0066401958465576,
      "learning_rate": 0.00013457943925233642,
      "loss": 0.7223,
      "step": 119
    },
    {
      "epoch": 1.1116279069767443,
      "grad_norm": 2.8901453018188477,
      "learning_rate": 0.00013317757009345793,
      "loss": 0.7577,
      "step": 120
    },
    {
      "epoch": 1.1209302325581396,
      "grad_norm": 1.9417037963867188,
      "learning_rate": 0.0001317757009345794,
      "loss": 0.305,
      "step": 121
    },
    {
      "epoch": 1.130232558139535,
      "grad_norm": 2.994821310043335,
      "learning_rate": 0.00013037383177570092,
      "loss": 1.1377,
      "step": 122
    },
    {
      "epoch": 1.1395348837209303,
      "grad_norm": 1.1230597496032715,
      "learning_rate": 0.0001289719626168224,
      "loss": 0.1209,
      "step": 123
    },
    {
      "epoch": 1.1488372093023256,
      "grad_norm": 2.880465269088745,
      "learning_rate": 0.0001275700934579439,
      "loss": 0.6622,
      "step": 124
    },
    {
      "epoch": 1.158139534883721,
      "grad_norm": 1.2167547941207886,
      "learning_rate": 0.0001261682242990654,
      "loss": 0.1055,
      "step": 125
    },
    {
      "epoch": 1.1674418604651162,
      "grad_norm": 4.612985134124756,
      "learning_rate": 0.0001247663551401869,
      "loss": 1.2956,
      "step": 126
    },
    {
      "epoch": 1.1767441860465115,
      "grad_norm": 2.87800669670105,
      "learning_rate": 0.00012336448598130838,
      "loss": 0.3976,
      "step": 127
    },
    {
      "epoch": 1.1860465116279069,
      "grad_norm": 0.8753928542137146,
      "learning_rate": 0.0001219626168224299,
      "loss": 0.084,
      "step": 128
    },
    {
      "epoch": 1.1953488372093024,
      "grad_norm": 4.710060119628906,
      "learning_rate": 0.00012056074766355139,
      "loss": 0.8872,
      "step": 129
    },
    {
      "epoch": 1.2046511627906977,
      "grad_norm": 2.1189026832580566,
      "learning_rate": 0.00011915887850467288,
      "loss": 0.1375,
      "step": 130
    },
    {
      "epoch": 1.213953488372093,
      "grad_norm": 0.852653980255127,
      "learning_rate": 0.00011775700934579438,
      "loss": 0.0848,
      "step": 131
    },
    {
      "epoch": 1.2232558139534884,
      "grad_norm": 3.8883657455444336,
      "learning_rate": 0.00011635514018691587,
      "loss": 1.2068,
      "step": 132
    },
    {
      "epoch": 1.2325581395348837,
      "grad_norm": 3.7358357906341553,
      "learning_rate": 0.00011495327102803737,
      "loss": 0.9501,
      "step": 133
    },
    {
      "epoch": 1.241860465116279,
      "grad_norm": 3.394519090652466,
      "learning_rate": 0.00011355140186915887,
      "loss": 0.5819,
      "step": 134
    },
    {
      "epoch": 1.2511627906976743,
      "grad_norm": 2.5351924896240234,
      "learning_rate": 0.00011214953271028036,
      "loss": 0.5398,
      "step": 135
    },
    {
      "epoch": 1.2604651162790699,
      "grad_norm": 2.956540584564209,
      "learning_rate": 0.00011074766355140186,
      "loss": 1.0483,
      "step": 136
    },
    {
      "epoch": 1.2697674418604652,
      "grad_norm": 1.5925813913345337,
      "learning_rate": 0.00010934579439252335,
      "loss": 0.471,
      "step": 137
    },
    {
      "epoch": 1.2790697674418605,
      "grad_norm": 1.9580110311508179,
      "learning_rate": 0.00010794392523364485,
      "loss": 0.4515,
      "step": 138
    },
    {
      "epoch": 1.2883720930232558,
      "grad_norm": 3.433852434158325,
      "learning_rate": 0.00010654205607476634,
      "loss": 0.96,
      "step": 139
    },
    {
      "epoch": 1.2976744186046512,
      "grad_norm": 1.026401400566101,
      "learning_rate": 0.00010514018691588784,
      "loss": 0.0719,
      "step": 140
    },
    {
      "epoch": 1.3069767441860465,
      "grad_norm": 1.9583760499954224,
      "learning_rate": 0.00010373831775700933,
      "loss": 0.3538,
      "step": 141
    },
    {
      "epoch": 1.3162790697674418,
      "grad_norm": 3.266057252883911,
      "learning_rate": 0.00010233644859813083,
      "loss": 0.6958,
      "step": 142
    },
    {
      "epoch": 1.3255813953488373,
      "grad_norm": 1.1610101461410522,
      "learning_rate": 0.00010093457943925232,
      "loss": 0.1876,
      "step": 143
    },
    {
      "epoch": 1.3348837209302324,
      "grad_norm": 3.2595272064208984,
      "learning_rate": 9.953271028037382e-05,
      "loss": 0.773,
      "step": 144
    },
    {
      "epoch": 1.344186046511628,
      "grad_norm": 1.8770215511322021,
      "learning_rate": 9.813084112149531e-05,
      "loss": 0.3923,
      "step": 145
    },
    {
      "epoch": 1.3534883720930233,
      "grad_norm": 2.1418330669403076,
      "learning_rate": 9.672897196261681e-05,
      "loss": 0.564,
      "step": 146
    },
    {
      "epoch": 1.3627906976744186,
      "grad_norm": 3.5923728942871094,
      "learning_rate": 9.53271028037383e-05,
      "loss": 0.945,
      "step": 147
    },
    {
      "epoch": 1.372093023255814,
      "grad_norm": 5.137239456176758,
      "learning_rate": 9.39252336448598e-05,
      "loss": 1.4073,
      "step": 148
    },
    {
      "epoch": 1.3813953488372093,
      "grad_norm": 1.8925820589065552,
      "learning_rate": 9.25233644859813e-05,
      "loss": 0.5194,
      "step": 149
    },
    {
      "epoch": 1.3906976744186046,
      "grad_norm": 4.616649150848389,
      "learning_rate": 9.112149532710279e-05,
      "loss": 1.1414,
      "step": 150
    },
    {
      "epoch": 1.4,
      "grad_norm": 0.733390212059021,
      "learning_rate": 8.971962616822429e-05,
      "loss": 0.0772,
      "step": 151
    },
    {
      "epoch": 1.4093023255813955,
      "grad_norm": 2.2707302570343018,
      "learning_rate": 8.831775700934578e-05,
      "loss": 0.2159,
      "step": 152
    },
    {
      "epoch": 1.4186046511627908,
      "grad_norm": 2.8133418560028076,
      "learning_rate": 8.691588785046728e-05,
      "loss": 0.8574,
      "step": 153
    },
    {
      "epoch": 1.427906976744186,
      "grad_norm": 2.7024266719818115,
      "learning_rate": 8.551401869158877e-05,
      "loss": 1.2072,
      "step": 154
    },
    {
      "epoch": 1.4372093023255814,
      "grad_norm": 1.7667391300201416,
      "learning_rate": 8.411214953271027e-05,
      "loss": 0.1095,
      "step": 155
    },
    {
      "epoch": 1.4465116279069767,
      "grad_norm": 0.8418726921081543,
      "learning_rate": 8.271028037383176e-05,
      "loss": 0.0868,
      "step": 156
    },
    {
      "epoch": 1.455813953488372,
      "grad_norm": 1.9447230100631714,
      "learning_rate": 8.130841121495326e-05,
      "loss": 0.2771,
      "step": 157
    },
    {
      "epoch": 1.4651162790697674,
      "grad_norm": 3.5185461044311523,
      "learning_rate": 7.990654205607475e-05,
      "loss": 0.4483,
      "step": 158
    },
    {
      "epoch": 1.474418604651163,
      "grad_norm": 5.251210689544678,
      "learning_rate": 7.850467289719625e-05,
      "loss": 1.7282,
      "step": 159
    },
    {
      "epoch": 1.483720930232558,
      "grad_norm": 1.3059910535812378,
      "learning_rate": 7.710280373831774e-05,
      "loss": 0.1658,
      "step": 160
    },
    {
      "epoch": 1.4930232558139536,
      "grad_norm": 1.5914368629455566,
      "learning_rate": 7.570093457943924e-05,
      "loss": 0.1471,
      "step": 161
    },
    {
      "epoch": 1.5023255813953489,
      "grad_norm": 2.389430284500122,
      "learning_rate": 7.429906542056073e-05,
      "loss": 0.4153,
      "step": 162
    },
    {
      "epoch": 1.5116279069767442,
      "grad_norm": 4.265838146209717,
      "learning_rate": 7.289719626168223e-05,
      "loss": 0.8113,
      "step": 163
    },
    {
      "epoch": 1.5209302325581395,
      "grad_norm": 3.2442057132720947,
      "learning_rate": 7.149532710280372e-05,
      "loss": 0.666,
      "step": 164
    },
    {
      "epoch": 1.5302325581395348,
      "grad_norm": 2.147632598876953,
      "learning_rate": 7.009345794392522e-05,
      "loss": 0.4622,
      "step": 165
    },
    {
      "epoch": 1.5395348837209304,
      "grad_norm": 4.531980037689209,
      "learning_rate": 6.869158878504672e-05,
      "loss": 1.0187,
      "step": 166
    },
    {
      "epoch": 1.5488372093023255,
      "grad_norm": 2.0679893493652344,
      "learning_rate": 6.728971962616821e-05,
      "loss": 0.3615,
      "step": 167
    },
    {
      "epoch": 1.558139534883721,
      "grad_norm": 0.5639179944992065,
      "learning_rate": 6.58878504672897e-05,
      "loss": 0.0424,
      "step": 168
    },
    {
      "epoch": 1.5674418604651161,
      "grad_norm": 4.217237949371338,
      "learning_rate": 6.44859813084112e-05,
      "loss": 0.8342,
      "step": 169
    },
    {
      "epoch": 1.5767441860465117,
      "grad_norm": 2.737750291824341,
      "learning_rate": 6.30841121495327e-05,
      "loss": 0.726,
      "step": 170
    },
    {
      "epoch": 1.586046511627907,
      "grad_norm": 4.46900749206543,
      "learning_rate": 6.168224299065419e-05,
      "loss": 0.7117,
      "step": 171
    },
    {
      "epoch": 1.5953488372093023,
      "grad_norm": 1.494213342666626,
      "learning_rate": 6.0280373831775694e-05,
      "loss": 0.1363,
      "step": 172
    },
    {
      "epoch": 1.6046511627906976,
      "grad_norm": 2.5123445987701416,
      "learning_rate": 5.887850467289719e-05,
      "loss": 0.7285,
      "step": 173
    },
    {
      "epoch": 1.613953488372093,
      "grad_norm": 7.165555477142334,
      "learning_rate": 5.7476635514018685e-05,
      "loss": 0.8607,
      "step": 174
    },
    {
      "epoch": 1.6232558139534885,
      "grad_norm": 3.0306410789489746,
      "learning_rate": 5.607476635514018e-05,
      "loss": 1.073,
      "step": 175
    },
    {
      "epoch": 1.6325581395348836,
      "grad_norm": 5.553063869476318,
      "learning_rate": 5.4672897196261676e-05,
      "loss": 1.7348,
      "step": 176
    },
    {
      "epoch": 1.6418604651162791,
      "grad_norm": 1.06315016746521,
      "learning_rate": 5.327102803738317e-05,
      "loss": 0.1372,
      "step": 177
    },
    {
      "epoch": 1.6511627906976745,
      "grad_norm": 2.806251287460327,
      "learning_rate": 5.1869158878504666e-05,
      "loss": 0.8382,
      "step": 178
    },
    {
      "epoch": 1.6604651162790698,
      "grad_norm": 1.01326584815979,
      "learning_rate": 5.046728971962616e-05,
      "loss": 0.1028,
      "step": 179
    },
    {
      "epoch": 1.669767441860465,
      "grad_norm": 0.5662851929664612,
      "learning_rate": 4.906542056074766e-05,
      "loss": 0.0653,
      "step": 180
    },
    {
      "epoch": 1.6790697674418604,
      "grad_norm": 4.713109970092773,
      "learning_rate": 4.766355140186915e-05,
      "loss": 0.989,
      "step": 181
    },
    {
      "epoch": 1.688372093023256,
      "grad_norm": 4.494734287261963,
      "learning_rate": 4.626168224299065e-05,
      "loss": 0.949,
      "step": 182
    },
    {
      "epoch": 1.697674418604651,
      "grad_norm": 0.9624391198158264,
      "learning_rate": 4.485981308411214e-05,
      "loss": 0.1063,
      "step": 183
    },
    {
      "epoch": 1.7069767441860466,
      "grad_norm": 1.9400463104248047,
      "learning_rate": 4.345794392523364e-05,
      "loss": 0.5751,
      "step": 184
    },
    {
      "epoch": 1.7162790697674417,
      "grad_norm": 4.661714553833008,
      "learning_rate": 4.2056074766355134e-05,
      "loss": 0.8604,
      "step": 185
    },
    {
      "epoch": 1.7255813953488373,
      "grad_norm": 3.1232025623321533,
      "learning_rate": 4.065420560747663e-05,
      "loss": 0.5365,
      "step": 186
    },
    {
      "epoch": 1.7348837209302326,
      "grad_norm": 0.9456319212913513,
      "learning_rate": 3.9252336448598124e-05,
      "loss": 0.0912,
      "step": 187
    },
    {
      "epoch": 1.744186046511628,
      "grad_norm": 2.6029746532440186,
      "learning_rate": 3.785046728971962e-05,
      "loss": 0.3077,
      "step": 188
    },
    {
      "epoch": 1.7534883720930232,
      "grad_norm": 1.1639633178710938,
      "learning_rate": 3.6448598130841115e-05,
      "loss": 0.1572,
      "step": 189
    },
    {
      "epoch": 1.7627906976744185,
      "grad_norm": 0.970963716506958,
      "learning_rate": 3.504672897196261e-05,
      "loss": 0.0862,
      "step": 190
    },
    {
      "epoch": 1.772093023255814,
      "grad_norm": 8.54854679107666,
      "learning_rate": 3.3644859813084105e-05,
      "loss": 1.8507,
      "step": 191
    },
    {
      "epoch": 1.7813953488372092,
      "grad_norm": 3.0481338500976562,
      "learning_rate": 3.22429906542056e-05,
      "loss": 0.5579,
      "step": 192
    },
    {
      "epoch": 1.7906976744186047,
      "grad_norm": 0.6486502885818481,
      "learning_rate": 3.0841121495327096e-05,
      "loss": 0.0683,
      "step": 193
    },
    {
      "epoch": 1.8,
      "grad_norm": 7.700622081756592,
      "learning_rate": 2.9439252336448595e-05,
      "loss": 0.6592,
      "step": 194
    },
    {
      "epoch": 1.8093023255813954,
      "grad_norm": 0.5065901875495911,
      "learning_rate": 2.803738317757009e-05,
      "loss": 0.0456,
      "step": 195
    },
    {
      "epoch": 1.8186046511627907,
      "grad_norm": 5.45478630065918,
      "learning_rate": 2.6635514018691585e-05,
      "loss": 1.123,
      "step": 196
    },
    {
      "epoch": 1.827906976744186,
      "grad_norm": 0.5418532490730286,
      "learning_rate": 2.523364485981308e-05,
      "loss": 0.0612,
      "step": 197
    },
    {
      "epoch": 1.8372093023255816,
      "grad_norm": 2.778184413909912,
      "learning_rate": 2.3831775700934576e-05,
      "loss": 0.8962,
      "step": 198
    },
    {
      "epoch": 1.8465116279069766,
      "grad_norm": 2.3851230144500732,
      "learning_rate": 2.242990654205607e-05,
      "loss": 0.1942,
      "step": 199
    },
    {
      "epoch": 1.8558139534883722,
      "grad_norm": 2.1156222820281982,
      "learning_rate": 2.1028037383177567e-05,
      "loss": 0.2987,
      "step": 200
    },
    {
      "epoch": 1.8651162790697673,
      "grad_norm": 2.3624958992004395,
      "learning_rate": 1.9626168224299062e-05,
      "loss": 0.6047,
      "step": 201
    },
    {
      "epoch": 1.8744186046511628,
      "grad_norm": 0.5786206126213074,
      "learning_rate": 1.8224299065420557e-05,
      "loss": 0.0762,
      "step": 202
    },
    {
      "epoch": 1.8837209302325582,
      "grad_norm": 1.0400969982147217,
      "learning_rate": 1.6822429906542053e-05,
      "loss": 0.1378,
      "step": 203
    },
    {
      "epoch": 1.8930232558139535,
      "grad_norm": 1.929383635520935,
      "learning_rate": 1.5420560747663548e-05,
      "loss": 0.5403,
      "step": 204
    },
    {
      "epoch": 1.9023255813953488,
      "grad_norm": 1.31123948097229,
      "learning_rate": 1.4018691588785045e-05,
      "loss": 0.0987,
      "step": 205
    },
    {
      "epoch": 1.9116279069767441,
      "grad_norm": 3.2365376949310303,
      "learning_rate": 1.261682242990654e-05,
      "loss": 1.129,
      "step": 206
    },
    {
      "epoch": 1.9209302325581397,
      "grad_norm": 2.4190316200256348,
      "learning_rate": 1.1214953271028036e-05,
      "loss": 0.5319,
      "step": 207
    },
    {
      "epoch": 1.9302325581395348,
      "grad_norm": 0.7270290851593018,
      "learning_rate": 9.813084112149531e-06,
      "loss": 0.0787,
      "step": 208
    },
    {
      "epoch": 1.9395348837209303,
      "grad_norm": 4.749324321746826,
      "learning_rate": 8.411214953271026e-06,
      "loss": 0.5635,
      "step": 209
    },
    {
      "epoch": 1.9488372093023256,
      "grad_norm": 0.5167117714881897,
      "learning_rate": 7.0093457943925225e-06,
      "loss": 0.0642,
      "step": 210
    }
  ],
  "logging_steps": 1,
  "max_steps": 214,
  "num_input_tokens_seen": 0,
  "num_train_epochs": 2,
  "save_steps": 10,
  "stateful_callbacks": {
    "TrainerControl": {
      "args": {
        "should_epoch_stop": false,
        "should_evaluate": false,
        "should_log": false,
        "should_save": true,
        "should_training_stop": false
      },
      "attributes": {}
    }
  },
  "total_flos": 2417217971945472.0,
  "train_batch_size": 1,
  "trial_name": null,
  "trial_params": null
}
